<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta http-equiv="content-type" content="text/html; charset=utf-8" />

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1" />

  <title>
    
      Yash Chandak &middot; Personal Webpage
    
  </title>

  


  <!-- CSS -->
  <link rel="stylesheet" href="/assets/css/main.css" />
  

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Abril+Fatface" />

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/favicon.png" />
<link rel="shortcut icon" href="/favicons/favicon.ico" />

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/feed.xml" />

  <!-- Additional head bits without overriding original head -->
</head>


  <body class="index home">

    <div id="sidebar">
  <center>
  <header>
    <img src="/images/dp.jpg" alt="">
    <h1 class="site-title">
      <a href="/">
        
        Yash Chandak
      </a>
    </h1>
    <p class="lead">ychandak@cs.umass.edu</p>

  </header>

  <p> <br>  </p>

  <nav id="sidebar-nav-links">
  
  

  

  


  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  

  
    
  

  
    
  

  
    
  

  


  


  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  
    
  

  

  
    
  

  
    
  

  
    
  

  


  <!-- Optional additional links to insert in sidebar nav -->
<a href="/docs/resume.pdf">CV/Resume</a>

</nav>

  <p> <br> </p>
  <!-- 
    <span class="site-version">Currently v3.4.1</span>
   -->

  <center>
<nav style="list-style: none; margin: auto; width: 85%; justify-content: center;" id="sidebar-icon-links">
  
    <a id="github-link"
       class="icon" title="Github Project" aria-label="Github Project"
       href="https://github.com/yashchandak" >
      <svg version="1.1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 28"><path d="M12 2c6.625 0 12 5.375 12 12 0 5.297-3.437 9.797-8.203 11.391-0.609 0.109-0.828-0.266-0.828-0.578 0-0.391 0.016-1.687 0.016-3.297 0-1.125-0.375-1.844-0.812-2.219 2.672-0.297 5.484-1.313 5.484-5.922 0-1.313-0.469-2.375-1.234-3.219 0.125-0.313 0.531-1.531-0.125-3.187-1-0.313-3.297 1.234-3.297 1.234-0.953-0.266-1.984-0.406-3-0.406s-2.047 0.141-3 0.406c0 0-2.297-1.547-3.297-1.234-0.656 1.656-0.25 2.875-0.125 3.187-0.766 0.844-1.234 1.906-1.234 3.219 0 4.594 2.797 5.625 5.469 5.922-0.344 0.313-0.656 0.844-0.766 1.609-0.688 0.313-2.438 0.844-3.484-1-0.656-1.141-1.844-1.234-1.844-1.234-1.172-0.016-0.078 0.734-0.078 0.734 0.781 0.359 1.328 1.75 1.328 1.75 0.703 2.141 4.047 1.422 4.047 1.422 0 1 0.016 1.937 0.016 2.234 0 0.313-0.219 0.688-0.828 0.578-4.766-1.594-8.203-6.094-8.203-11.391 0-6.625 5.375-12 12-12zM4.547 19.234c0.031-0.063-0.016-0.141-0.109-0.187-0.094-0.031-0.172-0.016-0.203 0.031-0.031 0.063 0.016 0.141 0.109 0.187 0.078 0.047 0.172 0.031 0.203-0.031zM5.031 19.766c0.063-0.047 0.047-0.156-0.031-0.25-0.078-0.078-0.187-0.109-0.25-0.047-0.063 0.047-0.047 0.156 0.031 0.25 0.078 0.078 0.187 0.109 0.25 0.047zM5.5 20.469c0.078-0.063 0.078-0.187 0-0.297-0.063-0.109-0.187-0.156-0.266-0.094-0.078 0.047-0.078 0.172 0 0.281s0.203 0.156 0.266 0.109zM6.156 21.125c0.063-0.063 0.031-0.203-0.063-0.297-0.109-0.109-0.25-0.125-0.313-0.047-0.078 0.063-0.047 0.203 0.063 0.297 0.109 0.109 0.25 0.125 0.313 0.047zM7.047 21.516c0.031-0.094-0.063-0.203-0.203-0.25-0.125-0.031-0.266 0.016-0.297 0.109s0.063 0.203 0.203 0.234c0.125 0.047 0.266 0 0.297-0.094zM8.031 21.594c0-0.109-0.125-0.187-0.266-0.172-0.141 0-0.25 0.078-0.25 0.172 0 0.109 0.109 0.187 0.266 0.172 0.141 0 0.25-0.078 0.25-0.172zM8.937 21.438c-0.016-0.094-0.141-0.156-0.281-0.141-0.141 0.031-0.234 0.125-0.219 0.234 0.016 0.094 0.141 0.156 0.281 0.125s0.234-0.125 0.219-0.219z"></path>
</svg>

    </a>
    <!-- <a id="github-download-link"
       class="icon" title="Download" aria-label="Download"
       href="https://github.com/yashchandak/archive/v3.4.1.zip">
      <svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M19 9h-4V3H9v6H5l7 7 7-7zM5 18v2h14v-2H5z"/>
    <path d="M0 0h24v24H0z" fill="none"/>
</svg>
    </a> -->
  

  
    <a id="twitter-link"
       class="icon" title="Twitter" aria-label="Twitter"
       href="https://twitter.com/chandakyash13">
      <?xml version="1.0" ?><!DOCTYPE svg  PUBLIC '-//W3C//DTD SVG 1.1//EN'  'http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd'><svg enable-background="new 0 0 56.693 56.693" height="56.693px" id="Layer_1" version="1.1" viewBox="0 0 56.693 56.693" width="56.693px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M28.348,5.157c-13.6,0-24.625,11.027-24.625,24.625c0,13.6,11.025,24.623,24.625,24.623c13.6,0,24.623-11.023,24.623-24.623  C52.971,16.184,41.947,5.157,28.348,5.157z M40.752,24.817c0.013,0.266,0.018,0.533,0.018,0.803c0,8.201-6.242,17.656-17.656,17.656  c-3.504,0-6.767-1.027-9.513-2.787c0.486,0.057,0.979,0.086,1.48,0.086c2.908,0,5.584-0.992,7.707-2.656  c-2.715-0.051-5.006-1.846-5.796-4.311c0.378,0.074,0.767,0.111,1.167,0.111c0.566,0,1.114-0.074,1.635-0.217  c-2.84-0.57-4.979-3.08-4.979-6.084c0-0.027,0-0.053,0.001-0.08c0.836,0.465,1.793,0.744,2.811,0.777  c-1.666-1.115-2.761-3.012-2.761-5.166c0-1.137,0.306-2.204,0.84-3.12c3.061,3.754,7.634,6.225,12.792,6.483  c-0.106-0.453-0.161-0.928-0.161-1.414c0-3.426,2.778-6.205,6.206-6.205c1.785,0,3.397,0.754,4.529,1.959  c1.414-0.277,2.742-0.795,3.941-1.506c-0.465,1.45-1.448,2.666-2.73,3.433c1.257-0.15,2.453-0.484,3.565-0.977  C43.018,22.849,41.965,23.942,40.752,24.817z"/></svg>





    </a>
  

   
    <a id="linkedin-link"
       class="icon" title="linkedin" aria-label="Linkedin"
       href="https://www.linkedin.com/in/yashchandak/">
      <?xml version="1.0" ?><!DOCTYPE svg  PUBLIC '-//W3C//DTD SVG 1.1//EN'  'http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd'><svg enable-background="new 0 0 56.693 56.693" height="56.693px" id="Layer_1" version="1.1" viewBox="0 0 56.693 56.693" width="56.693px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><g><path d="M30.071,27.101v-0.077c-0.016,0.026-0.033,0.052-0.05,0.077H30.071z"/><path d="M49.265,4.667H7.145c-2.016,0-3.651,1.596-3.651,3.563v42.613c0,1.966,1.635,3.562,3.651,3.562h42.12   c2.019,0,3.654-1.597,3.654-3.562V8.23C52.919,6.262,51.283,4.667,49.265,4.667z M18.475,46.304h-7.465V23.845h7.465V46.304z    M14.743,20.777h-0.05c-2.504,0-4.124-1.725-4.124-3.88c0-2.203,1.67-3.88,4.223-3.88c2.554,0,4.125,1.677,4.175,3.88   C18.967,19.052,17.345,20.777,14.743,20.777z M45.394,46.304h-7.465V34.286c0-3.018-1.08-5.078-3.781-5.078   c-2.062,0-3.29,1.389-3.831,2.731c-0.197,0.479-0.245,1.149-0.245,1.821v12.543h-7.465c0,0,0.098-20.354,0-22.459h7.465v3.179   c0.992-1.53,2.766-3.709,6.729-3.709c4.911,0,8.594,3.211,8.594,10.11V46.304z"/></g></svg>
    </a>
  

  
    <a id="facebook-link"
       class="icon" title="facebook" aria-label="Facebook"
       href="https://www.facebook.com/yashchandak.13">
      <?xml version="1.0" ?><!DOCTYPE svg  PUBLIC '-//W3C//DTD SVG 1.1//EN'  'http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd'><svg enable-background="new 0 0 56.693 56.693" height="56.693px" id="Layer_1" version="1.1" viewBox="0 0 56.693 56.693" width="56.693px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M40.43,21.739h-7.645v-5.014c0-1.883,1.248-2.322,2.127-2.322c0.877,0,5.395,0,5.395,0V6.125l-7.43-0.029  c-8.248,0-10.125,6.174-10.125,10.125v5.518h-4.77v8.53h4.77c0,10.947,0,24.137,0,24.137h10.033c0,0,0-13.32,0-24.137h6.77  L40.43,21.739z"/></svg>
    </a>
  

  
    <a id="scholar-link"
       class="icon" title="scholar" aria-label="Google Scholar"
       href="https://scholar.google.com/citations?user=AsgUcSEAAAAJ&hl=en&oi=ao">
      <?xml version="1.0" ?><!DOCTYPE svg  PUBLIC '-//W3C//DTD SVG 1.1//EN'  'http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd'><svg height="1755" width="1755" viewBox="0 0 1755 1755" xmlns="http://www.w3.org/2000/svg"><path transform="translate(0 1610) scale(1 -1)" d="M896.76 1130.189c-27.618 30.838-59.618 46.19-95.802 46.19-40.952 0-72.382-14.738-94.288-44.15-21.906-29.322-32.864-64.848-32.864-106.584 0-35.548 5.998-71.738 18-108.64 11.958-36.886 31.524-69.814 58.954-98.838 27.334-29.096 59.144-43.616 95.284-43.616 40.288 0 71.76 13.502 94.332 40.492 22.476 26.954 33.756 60.98 33.756 101.962 0 34.904-5.954 71.454-17.906 109.664-11.894 38.262-31.752 72.784-59.466 103.52zM1658.858 1512.573c-64.358 64.424-141.86 96.57-232.572 96.57h-1097.142c-90.712 0-168.14-32.146-232.572-96.57-64.424-64.286-96.57-141.86-96.57-232.572v-1097.142c0-90.712 32.146-168.288 96.57-232.712 64.432-64.146 142-96.432 232.572-96.432h1097.142c90.712 0 168.214 32.286 232.572 96.57 64.432 64.432 96.644 141.86 96.644 232.572v1097.142c0 90.712-32.22 168.288-96.644 232.572zM1297.81 1154.159v-392.126c0-18.154-14.856-33.016-33.016-33.016h-12.156c-18.162 0-33.016 14.856-33.016 33.016v392.126c0 16.12-2.34 29.578 20.188 32.41v52.172l-173.43-142.24c2.004-3.716 3.906-6.092 5.712-9.208 15.242-26.976 23.004-60.526 23.004-101.53 0-31.43-5.238-59.662-15.858-84.598-10.57-24.928-23.428-45.29-38.43-60.972-15.002-15.74-30.048-30.128-45.092-43.074-15.046-12.976-27.904-26.506-38.436-40.55-10.614-14-15.894-28.474-15.894-43.476 0-15.024 6.854-30.288 20.524-45.67 13.62-15.426 30.376-30.376 50.19-45.144 19.85-14.666 39.658-30.946 59.472-48.662 19.858-17.694 36.52-40.456 50.14-68.096 13.722-27.744 20.568-58.288 20.568-91.86 0-44.288-11.294-84.282-33.806-119.882-22.58-35.446-51.998-63.73-88.144-84.472-36.242-20.882-75-36.6-116.334-47.214-41.42-10.518-82.52-15.806-123.568-15.806-25.908 0-52.048 1.996-78.336 6.1-26.382 4.096-52.81 11.33-79.426 21.526-26.668 10.262-50.286 22.864-70.758 37.998-20.524 14.98-37.046 34.312-49.716 57.856-12.668 23.552-18.958 50.022-18.958 79.426 0 34.882 9.714 67.24 29.192 97.404 19.478 29.944 45.282 54.952 77.378 74.76 55.998 34.838 143.858 56.364 263.432 64.498-27.334 34.172-41.048 66.334-41.048 96.432 0 17.122 4.476 35.474 13.334 55.288-14.284-1.996-28.994-3.124-44.002-3.124-64.234 0-118.476 20.882-162.524 62.932-44.046 41.976-66.048 94.522-66.048 158.048 0 6.642 0.19 12.492 0.672 18.974h-261.046l393.618 342.17h651.856l-60.24-47.024v-82.996c22.368-2.874 20.004-16.318 20.004-32.394zM900.382 544.929c-7.52 1.36-18.088 2.122-31.708 2.122-29.382 0-58.288-2.596-86.666-7.782-28.38-5.046-56.378-13.568-83.998-25.592-27.722-11.952-50.096-29.528-67.146-52.766-17.144-23.208-25.666-50.542-25.666-81.994 0-29.974 7.52-56.714 22.572-80.004 15.002-23.142 34.808-41.26 59.428-54.236 24.62-12.998 50.432-22.814 77.378-29.264 26.998-6.408 54.476-9.736 82.476-9.736 55.376 0 103.050 12.47 143.046 37.406 39.906 24.928 59.904 63.422 59.904 115.382 0 10.928-1.522 21.686-4.528 32.19-3.138 10.62-6.24 19.712-9.282 27.26-3.050 7.41-8.858 16.332-17.43 26.616-8.522 10.314-15.046 17.934-19.434 23.004-4.476 5.238-12.852 12.712-25.19 22.594-12.236 9.926-20.048 16.114-23.522 18.402-3.43 2.406-12.332 8.908-26.668 19.456-14.328 10.634-22.184 16.274-23.566 16.94z" /></svg>

    </a>
  
  <!--<a id="subscribe-link"
     class="icon" title="Subscribe" aria-label="Subscribe"
     href="/feed.xml">
    <svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M0 0h24v24H0z" fill="none"/>
    <circle cx="6.18" cy="17.82" r="2.18"/>
    <path d="M4 4.44v2.83c7.03 0 12.73 5.7 12.73 12.73h2.83c0-8.59-6.97-15.56-15.56-15.56zm0 5.66v2.83c3.9 0 7.07 3.17 7.07 7.07h2.83c0-5.47-4.43-9.9-9.9-9.9z"/>
</svg>
  </a>

  
  
  
  

  
    <a id="tags-link"
       class="icon"
       title="Tags" aria-label="Tags"
       href="/tags.html">
      <svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M0 0h24v24H0z" fill="none"/>
    <path d="M17.63 5.84C17.27 5.33 16.67 5 16 5L5 5.01C3.9 5.01 3 5.9 3 7v10c0 1.1.9 1.99 2 1.99L16 19c.67 0 1.27-.33 1.63-.84L22 12l-4.37-6.16z"/>
</svg>
    </a>
  

  
    <a id="search-link"
       class="icon"
       title="Search" aria-label="Tags"
       href="/search.html">
      <svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"/>
    <path d="M0 0h24v24H0z" fill="none"/>
</svg>
    </a>
  -->

  <!-- Optional additional links to insert for icons links -->
</nav>
 </center>
  <p style="font-size:80%;">
  (Site last updated: Oct, 2018)
  <br />
  <a href="https://github.com/fongandrew/hydeout">Theme by Hydeout</a>
</p>

  </center>
</div>

    <main class="container">
      <div class="content">
  

  
  

  

  
  

  

  
  

  

  
  

  

  
  

  

  
  <article class="post-body">
    <h2 class="post-title">
      <a href="/_pages/homepage.html">
        About
      </a>
    </h2>
    <div class="post-meta">
  

  <span class="post-categories">
    
  </span>
</div>

    <style>

table {
  margin-bottom: 1rem;
  width: 100%;
  font-size: 85%;
  border: 0px solid $border-color;
  border-collapse: collapse;
}

td,
th {
  padding: .25rem .5rem;
  border: 0px solid $border-color;
}

th {
  text-align: left;
}

tbody tr:nth-child(odd) td,
tbody tr:nth-child(odd) th {
  background-color: transparent;
}

paper {
 color: #; 
 font-weight:bold;
}
</style>

<p><br /></p>

<p>I’m a second year MS/PhD student at <a href="https://www.umass.edu/">University of Massachusetts, Amherst</a> fortunate to be advised by <a href="https://people.cs.umass.edu/~pthomas/">Prof. Philip Thomas</a>.
My research interests are in <strong>continual learning</strong>, a branch of Artificial Intelligence, which aims at teaching machines
new concepts over time. My work is concentrated around the intersection of reinforcement learning,
optimization and machine learning. I enjoy reading and looking out for inspirations from neuroscience as well.</p>

<p>I completed by B.Tech in Computer Science at <a href="http://chennai.vit.ac.in/">VIT University</a> in 2017, where <a href="https://www.researchgate.net/scientific-contributions/2046556969_PS_Nithya_Darisini">Prof. Nithya Darisini</a> was my mentor. I was also fortunate to spend most of my senior year at <a href="https://www.iitm.ac.in">IIT-Madras</a> under the guidance of
<a href="https://www.cse.iitm.ac.in/~ravi/">Prof. B. Ravindran</a>. In my Junior year, I had a great time learning at <a href="https://www.drdo.gov.in/drdo/labs1/IRDE/English/indexnew.jsp?pg=homepage.jsp">Defence Research and Development Organization(IRDE, DRDO)</a>
under Dr. J.P. Singh and later at <a href="http://www.utt.fr/en/index.html">University of Technology, Troyes, France</a> with <a href="https://scholar.google.com/citations?user=qHEWWZ8AAAAJ&amp;hl=en">Prof. Babiga Birregah</a>.
During my sophomore days, I was introduced to machine learning research by
<a href="https://users.soe.ucsc.edu/~davis/">Prof. James Davis</a>, UCSC, and <a href="https://stanford.edu/~rvaish/">Rajan Vaish</a>, Stanford, through their large-scale research initiative:
<a href="https://aspiringresearchers.soe.ucsc.edu/">Aspiring Researcher’s Challenge</a>.
Before that, I was a national level basketball player in India and used to play all day everyday.</p>

<p><br /></p>
<h2 id="recent">Recent</h2>

<ul>
  <li>Interned at Adobe Research under <a href="https://research.adobe.com/person/georgios-theocharous/">Dr. Georgios Theocharous</a> during Summer 2018.</li>
</ul>

<p><br /><br /></p>

<h2 id="publications">Publications</h2>

<h4 id="2018">2018</h4>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
   <tr>
     <td width="12%" valign="top">
            <img src="/images/publications/dynamic_action.png" alt="dynamic_actions" align="top" style="width: 80%; margin:0px 10px; border-radius:0%" /> 
     </td>
     <td valign="top" width="85%">
          <p>
              <paper>Reinforcement Learning with a Dynamic Action Set</paper>
              <br />
              <b>Yash Chandak</b>, 
              <a href="https://research.adobe.com/person/georgios-theocharous/">Georgios Theocharous</a>,   
              <a href="https://people.cs.umass.edu/~jekostas/jekostas.html">James Kostas</a>, 
              <a href="https://people.cs.umass.edu/~pthomas/">Philip Thomas</a>
              <br />
              (Under review)
              <!-- [<a href="">Arxiv</a>, <a href="">Code</a>] -->
              <details>
                <summary>Abstract</summary>            
                  <p class="message">
                    Reinforcement learning has been successfully applied to many sequential decision making problems, where the set of possible actions (possible decisions) is fixed. However, in many real-world settings, the set of possible actions can change over time.  We present a model-free method to continually adapt to a dynamic set of possible actions. We show how a policy can be decomposed into an internal policy that acts in a space of action representations and a reward-independent component that transforms these representations into actual actions.  These representations not only make the internal policy parameterization invariant to the cardinality of the action set, but also improve generalization by allowing the agent to infer the outcomes of actions similar to actions already taken. We provide an algorithm to autonomously adapt to this dynamic action set by exploiting structure in the space of actions using supervised learning while learning the internal policy using policy gradient.  The efficacy of the proposed method is demonstrated on large-scale real-world continual learning problems. 
                  </p>
              </details>
          </p>  
     </td>
   </tr>

   <tr>
     <td width="12%" valign="top">
            <img src="/images/publications/action_rep.png" alt="action_representations" align="top" style="width: 80%; margin:0px 10px; border-radius:0%" /> 
     </td>
     <td valign="top" width="85%">
          <p>
              <paper>Improving Generalization by Learning Action Representations for Reinforcement Learning</paper>
              <br />
              <b>Yash Chandak</b>, 
              <a href="https://research.adobe.com/person/georgios-theocharous/">Georgios Theocharous</a>,   
              <a href="https://people.cs.umass.edu/~jekostas/jekostas.html">James Kostas</a>, 
              <a href="https://people.cs.umass.edu/~pthomas/">Philip Thomas</a>
              <br />
              (Under review)
              <!-- [<a href="">Arxiv</a>, <a href="">Code</a>] -->
              <details>
                <summary>Abstract</summary>            
                  <p class="message">
                    Most  model-free  reinforcement  learning  methods  leverage state representations (embeddings) for generalization but either  ignore  structure  in  the  space  of  actions  or  assume the  structure  is  provided a  priori. We  show  how  a  policy can  be  decomposed  into  a  component  that  acts  in  a  lower-dimensional  space  of  action  representations  and  a  component that transforms these representations into actual actions. These representations help to improve generalization by allowing the agent to infer the outcomes of actions similar to actions already taken. We provide an algorithm, along with a  proof  of  its  convergence,  to  both  learn  and  use  these  action representations efficiently. The efficacy of the proposed method is demonstrated on large-scale real-world problems.
                  </p>
              </details>
          </p>  
     </td>
   </tr>

   <tr>
     <td width="12%" valign="top">
            <img src="/images/publications/fgcn.png" alt="FGCN" align="top" style="width: 80%; margin:0px 10px; border-radius:0%" /> 
     </td>
     <td valign="top" width="85%">
          <p>
              <paper>Fusion Graph Convolutional Networks</paper>
              <br />
              <a href="https://priyeshv.github.io/">Priyesh Vijayan</a>
              <b>Yash Chandak</b>, 
              <a href="https://www.cse.iitm.ac.in/~miteshk/">Mitesh Khapra</a>,   
              <a href="https://www.cse.iitm.ac.in/~ravi/">Balaraman Ravindran</a>
              <br />
              14th International Workshop on Machine Learning with Graphs, 24th ACM SIGKDD Conference on
Knowledge Discovery and Data Mining (KDD 2018).
              [<a href="https://arxiv.org/abs/1805.12528">Arxiv</a>, <a href="https://github.com/PriyeshV/HOPF">Code</a>] 
              <details>
                <summary>Abstract</summary>            
                  <p class="message">
                     Semi-supervised node classification in attributed graphs, i.e., graphs with node features, involves learning to classify unlabeled nodes given a partially labeled graph. Label predictions are made by jointly modeling the node and its' neighborhood features. State-of-the-art models for node classification on such attributed graphs use differentiable recursive functions that enable aggregation and filtering of neighborhood information from multiple hops. In this work, we analyze the representation capacity of these models to regulate information from multiple hops independently. From our analysis, we conclude that these models despite being powerful, have limited representation capacity to capture multi-hop neighborhood information effectively. Further, we also propose a mathematically motivated, yet simple extension to existing graph convolutional networks (GCNs) which has improved representation capacity. We extensively evaluate the proposed model, F-GCN on eight popular datasets from different domains. F-GCN outperforms the state-of-the-art models for semi-supervised learning on six datasets while being extremely competitive on the other two. 
                  </p>
              </details>
          </p>  
     </td>
   </tr>
      
   <tr>
     <td width="12%" valign="top">
            <img src="/images/publications/hopf.png" alt="HOPF" align="top" style="width: 80%; margin:0px 10px; border-radius:0%" /> 
     </td>
     <td valign="top" width="85%">
          <p>
              <paper>HOPF: Higher Order Propagation Framework for Deep Collective Classification</paper>
              <br />
              <a href="https://priyeshv.github.io/">Priyesh Vijayan</a>
              <b>Yash Chandak</b>, 
              <a href="https://www.cse.iitm.ac.in/~miteshk/">Mitesh Khapra</a>,   
              <a href="https://www.cse.iitm.ac.in/~ravi/">Balaraman Ravindran</a>
              <br />
              Eighth International Workshop on Statistical Relational AI at the 27th International Joint Conference on
Artificial Intelligence (IJCAI 2018).
              [<a href="https://arxiv.org/abs/1805.12421">Arxiv</a>, <a href="https://github.com/PriyeshV/HOPF">Code</a>] 
              <details>
                <summary>Abstract</summary>            
                  <p class="message">
                     Given a graph where every node has certain attributes associated with it and some nodes have labels associated with them, Collective Classification (CC) is the task of assigning labels to every unlabeled node using information from the node as well as its neighbors. It is often the case that a node is not only influenced by its immediate neighbors but also by higher order neighbors, multiple hops away. Recent state-of-the-art models for CC learn end-to-end differentiable variations of Weisfeiler-Lehman (WL) kernels to aggregate multi-hop neighborhood information. In this work, we propose a Higher Order Propagation Framework, HOPF, which provides an iterative inference mechanism for these powerful differentiable kernels. Such a combination of classical iterative inference mechanism with recent differentiable kernels allows the framework to learn graph convolutional filters that simultaneously exploit the attribute and label information available in the neighborhood. Further, these iterative differentiable kernels can scale to larger hops beyond the memory limitations of existing differentiable kernels. We also show that existing WL kernel-based models suffer from the problem of Node Information Morphing where the information of the node is morphed or overwhelmed by the information of its neighbors when considering multiple hops. To address this, we propose a specific instantiation of HOPF, called the NIP models, which preserves the node information at every propagation step. The iterative formulation of NIP models further helps in incorporating distant hop information concisely as summaries of the inferred labels. We do an extensive evaluation across 11 datasets from different domains. We show that existing CC models do not provide consistent performance across datasets, while the proposed NIP model with iterative inference is more robust.
                  </p>
              </details>
          </p>  
     </td>
   </tr>
   
</table>

<h4 id="2015">2015</h4>

<table>
   <tr>
     <td width="12%" valign="top">
            <img src="/images/publications/human_machine.png" alt="Human-Machine" align="top" style="width: 80%; margin:0px 10px; border-radius:0%" /> 
     </td>
     <td valign="top" width="85%">
          <p>
              <paper>On Optimizing Human-Machine Task Assignment</paper>
              <br />
              <a href="https://www.cs.cornell.edu/~andreas/">Andreas Veit</a>,
              <a href="http://mjwilber.org/">Michael Wilber</a>,
              <a href="http://www.rajanvaish.com/index.html">Rajan Vaish</a>,
              <a href="https://tech.cornell.edu/people/serge-belongie/">Serge Belongie</a>,
              <a href="https://users.soe.ucsc.edu/~davis/">James Davis</a>,
              <b>Others</b>
              <br />
              The thrid AAAI Conference on Human Computation and Crowdsourcing (wip) (HCOMP 2015).
              [<a href="https://arxiv.org/pdf/1509.07543.pdf">Arxiv</a>] 
              <details>
                <summary>Abstract</summary>            
                  <p class="message">
                     When crowdsourcing systems are used in combination with machine inference systems in the real world, they benefit the most when the machine system is deeply integrated with the crowd workers. However, if researchers wish to integrate the crowd with "off-the-shelf" machine classifiers, this deep integration is not always possible. This work explores two strategies to increase accuracy and decrease cost under this setting. First, we show that reordering tasks presented to the human can create a significant accuracy improvement. Further, we show that greedily choosing parameters to maximize machine accuracy is sub-optimal, and joint optimization of the combined system improves performance. 
                  </p>
              </details>
          </p>  
     </td>
   </tr>
</table>

<p><br /><br /></p>

<h2 id="courses">Courses</h2>

<ul>
  <li><a href="http://openscholar.cs.umass.edu/marlin/classes/compsci-689-machine-learning">CS 689: Machine Learning</a></li>
  <li><a href="https://people.cs.umass.edu/~arya/courses/650/CS650-2016.html">CS 650: Applied Information Theory</a></li>
  <li><a href="https://people.cs.umass.edu/~ramesh/Site/TEACHING.html">CS 611: Advanced Algorithms</a></li>
  <li><a href="http://people.math.umass.edu/~dobson/Math645/index.html">MATH 645: ODEs and Dynamical Systems</a></li>
  <li><a href="https://www.cse.iitm.ac.in/~ravi/teaching.html">CS 6700: Reinforcement Learning</a></li>
  <li><a href="https://www.cse.iitm.ac.in/~miteshk/CS7015.html">CS 7015: Deep Learning</a></li>
</ul>

<p><br /><br /></p>
<h2 id="lab-talks">Lab Talks</h2>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
   <tr>
     <td width="7%" valign="top">
            <img src="/images/talks/action_rep.png" alt="action_rep" align="top" style="width: 80%; margin:0px 10px; border-radius:0%" /> 
     </td>
     <td valign="middle" width="85%">
          <p>
            <b>Improving Generalization by Learning
 Action Representations for Reinforcement Learning.</b>
            <br />
            Autonomous Learning Lab, UMass, 2018. [<a href="https://docs.google.com/presentation/d/1g8v-8Bje6WhUAjcZ4I46gFmoo5thAe4rautrQ3o0gMY/edit?usp=sharing">Slides</a>]
          </p>  
     </td>
   </tr>
   
   <tr>
     <td width="7%" valign="top">
            <img src="/images/talks/zap.png" alt="ZapQ" align="top" style="width: 80%; margin:0px 10px; border-radius:0%" /> 
     </td>
     <td valign="middle" width="85%">
          <p>
            <b>Faster convergence for Q-Learning using Zap-Q.</b>
            <br />
            Autonomous Learning Lab, UMass, 2017. [<a href="https://docs.google.com/presentation/d/1kczu1I8HDtOf6VI8rBHlJ9v4w2NDzFbBf8oqo9_iEBQ/edit?usp=sharing">Slides</a>]
          </p>  
     </td>
   </tr>

   <tr>
     <td width="7%" valign="top">
            <img src="/images/talks/talk_lifelong.png" alt="talk_lifelong" align="top" style="width: 80%; margin:0px 10px; border-radius:0%" /> 
     </td>
     <td valign="middle" width="85%">
          <p>
            <b>Life-long learning, overcoming catastrophic forgetting in Neural Netowrks.</b>
            <br />
            RISE lab, IIT-Madras, 2017. [<a href="https://docs.google.com/presentation/d/1gcaM2Q6wfpQ4da8KTaCOFaEBpkjTyd_8XJHpygSLF58/edit?usp=sharing">Slides</a>]
          </p>  
     </td>
   </tr>      
</table>



  </article>
  
  

  

  
  

  

  
  

  

  
  

  

  
  

  

  
  

  

  
  
</div>
    </main>

    <!-- Optional footer content -->

    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-128250681-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-128250681-1');
</script>

  </body>
</html>
