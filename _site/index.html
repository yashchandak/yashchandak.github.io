<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta http-equiv="content-type" content="text/html; charset=utf-8" />

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1" />

  <title>
    
      Yash Chandak &middot; Personal Webpage
    
  </title>

  


  <!-- CSS -->
  <link rel="stylesheet" href="/assets/css/main.css" />
  

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Abril+Fatface" />

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/favicon.png" />
<link rel="shortcut icon" href="/favicons/favicon.ico" />

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/feed.xml" />

  <!-- Additional head bits without overriding original head -->


  <!-- Mathjax Support -->
  <script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>

</head>


  <body class="index home">

    <div id="sidebar">
  <center>

  <header>
    <img src="/images/dp.jpg" alt="" width="75%" align="center" > 
    <h1 class="site-title">
      <a href="/">
        
        Yash Chandak
      </a>
    </h1>
    <p class="lead">y[lastname]@stanford.edu</p>

  </header>

  <p>
    <br>


  <nav id="sidebar-nav-links">
  
    <a class="home-link  active"
        href="/">Home</a>
  

  

  


  
    
  

  
    
  

  
    
  

  
    
  

  

  

  
    
  

  
    
  

  
    
  

  

  


  
    
  

  
    
  

  
    
  

  
    
  

  

  

  
    
  

  

  
    
      <a class="page-link "
          href="/publication/">Publications</a>
    
  

  
    
      <a class="page-link "
          href="/about/">About Me</a>
    
  


  
    <a class="page-link "
	href="/blog/">Blog</a>
  

  <!-- Optional additional links to insert in sidebar nav -->
<!-- <a href="/docs/resume.pdf">CV/Resume</a> -->

</nav>


  <p>
    <br>
  </p>

  <!-- 
    <span class="site-version">Currently v3.4.1</span>
   -->

  <center>
<nav style="list-style: none; margin: auto; width: 85%; justify-content: center;" id="sidebar-icon-links">
  
    <a id="github-link"
       class="icon" title="Github Project" aria-label="Github Project"
       href="https://github.com/yashchandak" >
      <svg version="1.1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 28"><path d="M12 2c6.625 0 12 5.375 12 12 0 5.297-3.437 9.797-8.203 11.391-0.609 0.109-0.828-0.266-0.828-0.578 0-0.391 0.016-1.687 0.016-3.297 0-1.125-0.375-1.844-0.812-2.219 2.672-0.297 5.484-1.313 5.484-5.922 0-1.313-0.469-2.375-1.234-3.219 0.125-0.313 0.531-1.531-0.125-3.187-1-0.313-3.297 1.234-3.297 1.234-0.953-0.266-1.984-0.406-3-0.406s-2.047 0.141-3 0.406c0 0-2.297-1.547-3.297-1.234-0.656 1.656-0.25 2.875-0.125 3.187-0.766 0.844-1.234 1.906-1.234 3.219 0 4.594 2.797 5.625 5.469 5.922-0.344 0.313-0.656 0.844-0.766 1.609-0.688 0.313-2.438 0.844-3.484-1-0.656-1.141-1.844-1.234-1.844-1.234-1.172-0.016-0.078 0.734-0.078 0.734 0.781 0.359 1.328 1.75 1.328 1.75 0.703 2.141 4.047 1.422 4.047 1.422 0 1 0.016 1.937 0.016 2.234 0 0.313-0.219 0.688-0.828 0.578-4.766-1.594-8.203-6.094-8.203-11.391 0-6.625 5.375-12 12-12zM4.547 19.234c0.031-0.063-0.016-0.141-0.109-0.187-0.094-0.031-0.172-0.016-0.203 0.031-0.031 0.063 0.016 0.141 0.109 0.187 0.078 0.047 0.172 0.031 0.203-0.031zM5.031 19.766c0.063-0.047 0.047-0.156-0.031-0.25-0.078-0.078-0.187-0.109-0.25-0.047-0.063 0.047-0.047 0.156 0.031 0.25 0.078 0.078 0.187 0.109 0.25 0.047zM5.5 20.469c0.078-0.063 0.078-0.187 0-0.297-0.063-0.109-0.187-0.156-0.266-0.094-0.078 0.047-0.078 0.172 0 0.281s0.203 0.156 0.266 0.109zM6.156 21.125c0.063-0.063 0.031-0.203-0.063-0.297-0.109-0.109-0.25-0.125-0.313-0.047-0.078 0.063-0.047 0.203 0.063 0.297 0.109 0.109 0.25 0.125 0.313 0.047zM7.047 21.516c0.031-0.094-0.063-0.203-0.203-0.25-0.125-0.031-0.266 0.016-0.297 0.109s0.063 0.203 0.203 0.234c0.125 0.047 0.266 0 0.297-0.094zM8.031 21.594c0-0.109-0.125-0.187-0.266-0.172-0.141 0-0.25 0.078-0.25 0.172 0 0.109 0.109 0.187 0.266 0.172 0.141 0 0.25-0.078 0.25-0.172zM8.937 21.438c-0.016-0.094-0.141-0.156-0.281-0.141-0.141 0.031-0.234 0.125-0.219 0.234 0.016 0.094 0.141 0.156 0.281 0.125s0.234-0.125 0.219-0.219z"></path>
</svg>

    </a>
    <!-- <a id="github-download-link"
       class="icon" title="Download" aria-label="Download"
       href="https://github.com/yashchandak/archive/v3.4.1.zip">
      <svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M19 9h-4V3H9v6H5l7 7 7-7zM5 18v2h14v-2H5z"/>
    <path d="M0 0h24v24H0z" fill="none"/>
</svg>
    </a> -->
  

  
    <a id="twitter-link"
       class="icon" title="Twitter" aria-label="Twitter"
       href="https://twitter.com/chandakyash13">
      <?xml version="1.0" ?><!DOCTYPE svg  PUBLIC '-//W3C//DTD SVG 1.1//EN'  'http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd'><svg enable-background="new 0 0 56.693 56.693" height="56.693px" id="Layer_1" version="1.1" viewBox="0 0 56.693 56.693" width="56.693px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M28.348,5.157c-13.6,0-24.625,11.027-24.625,24.625c0,13.6,11.025,24.623,24.625,24.623c13.6,0,24.623-11.023,24.623-24.623  C52.971,16.184,41.947,5.157,28.348,5.157z M40.752,24.817c0.013,0.266,0.018,0.533,0.018,0.803c0,8.201-6.242,17.656-17.656,17.656  c-3.504,0-6.767-1.027-9.513-2.787c0.486,0.057,0.979,0.086,1.48,0.086c2.908,0,5.584-0.992,7.707-2.656  c-2.715-0.051-5.006-1.846-5.796-4.311c0.378,0.074,0.767,0.111,1.167,0.111c0.566,0,1.114-0.074,1.635-0.217  c-2.84-0.57-4.979-3.08-4.979-6.084c0-0.027,0-0.053,0.001-0.08c0.836,0.465,1.793,0.744,2.811,0.777  c-1.666-1.115-2.761-3.012-2.761-5.166c0-1.137,0.306-2.204,0.84-3.12c3.061,3.754,7.634,6.225,12.792,6.483  c-0.106-0.453-0.161-0.928-0.161-1.414c0-3.426,2.778-6.205,6.206-6.205c1.785,0,3.397,0.754,4.529,1.959  c1.414-0.277,2.742-0.795,3.941-1.506c-0.465,1.45-1.448,2.666-2.73,3.433c1.257-0.15,2.453-0.484,3.565-0.977  C43.018,22.849,41.965,23.942,40.752,24.817z"/></svg>





    </a>
  

   
    <a id="linkedin-link"
       class="icon" title="linkedin" aria-label="Linkedin"
       href="https://www.linkedin.com/in/yashchandak/">
      <?xml version="1.0" ?><!DOCTYPE svg  PUBLIC '-//W3C//DTD SVG 1.1//EN'  'http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd'><svg enable-background="new 0 0 56.693 56.693" height="56.693px" id="Layer_1" version="1.1" viewBox="0 0 56.693 56.693" width="56.693px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><g><path d="M30.071,27.101v-0.077c-0.016,0.026-0.033,0.052-0.05,0.077H30.071z"/><path d="M49.265,4.667H7.145c-2.016,0-3.651,1.596-3.651,3.563v42.613c0,1.966,1.635,3.562,3.651,3.562h42.12   c2.019,0,3.654-1.597,3.654-3.562V8.23C52.919,6.262,51.283,4.667,49.265,4.667z M18.475,46.304h-7.465V23.845h7.465V46.304z    M14.743,20.777h-0.05c-2.504,0-4.124-1.725-4.124-3.88c0-2.203,1.67-3.88,4.223-3.88c2.554,0,4.125,1.677,4.175,3.88   C18.967,19.052,17.345,20.777,14.743,20.777z M45.394,46.304h-7.465V34.286c0-3.018-1.08-5.078-3.781-5.078   c-2.062,0-3.29,1.389-3.831,2.731c-0.197,0.479-0.245,1.149-0.245,1.821v12.543h-7.465c0,0,0.098-20.354,0-22.459h7.465v3.179   c0.992-1.53,2.766-3.709,6.729-3.709c4.911,0,8.594,3.211,8.594,10.11V46.304z"/></g></svg>
    </a>
  

  
    <a id="facebook-link"
       class="icon" title="facebook" aria-label="Facebook"
       href="https://www.facebook.com/yashchandak.13">
      <?xml version="1.0" ?><!DOCTYPE svg  PUBLIC '-//W3C//DTD SVG 1.1//EN'  'http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd'><svg enable-background="new 0 0 56.693 56.693" height="56.693px" id="Layer_1" version="1.1" viewBox="0 0 56.693 56.693" width="56.693px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M40.43,21.739h-7.645v-5.014c0-1.883,1.248-2.322,2.127-2.322c0.877,0,5.395,0,5.395,0V6.125l-7.43-0.029  c-8.248,0-10.125,6.174-10.125,10.125v5.518h-4.77v8.53h4.77c0,10.947,0,24.137,0,24.137h10.033c0,0,0-13.32,0-24.137h6.77  L40.43,21.739z"/></svg>
    </a>
  

  
    <a id="scholar-link"
       class="icon" title="scholar" aria-label="Google Scholar"
       href="https://scholar.google.com/citations?user=OAUZgecAAAAJ&hl=en&oi=ao">
      <?xml version="1.0" ?><!DOCTYPE svg  PUBLIC '-//W3C//DTD SVG 1.1//EN'  'http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd'><svg height="1755" width="1755" viewBox="0 0 1755 1755" xmlns="http://www.w3.org/2000/svg"><path transform="translate(0 1610) scale(1 -1)" d="M896.76 1130.189c-27.618 30.838-59.618 46.19-95.802 46.19-40.952 0-72.382-14.738-94.288-44.15-21.906-29.322-32.864-64.848-32.864-106.584 0-35.548 5.998-71.738 18-108.64 11.958-36.886 31.524-69.814 58.954-98.838 27.334-29.096 59.144-43.616 95.284-43.616 40.288 0 71.76 13.502 94.332 40.492 22.476 26.954 33.756 60.98 33.756 101.962 0 34.904-5.954 71.454-17.906 109.664-11.894 38.262-31.752 72.784-59.466 103.52zM1658.858 1512.573c-64.358 64.424-141.86 96.57-232.572 96.57h-1097.142c-90.712 0-168.14-32.146-232.572-96.57-64.424-64.286-96.57-141.86-96.57-232.572v-1097.142c0-90.712 32.146-168.288 96.57-232.712 64.432-64.146 142-96.432 232.572-96.432h1097.142c90.712 0 168.214 32.286 232.572 96.57 64.432 64.432 96.644 141.86 96.644 232.572v1097.142c0 90.712-32.22 168.288-96.644 232.572zM1297.81 1154.159v-392.126c0-18.154-14.856-33.016-33.016-33.016h-12.156c-18.162 0-33.016 14.856-33.016 33.016v392.126c0 16.12-2.34 29.578 20.188 32.41v52.172l-173.43-142.24c2.004-3.716 3.906-6.092 5.712-9.208 15.242-26.976 23.004-60.526 23.004-101.53 0-31.43-5.238-59.662-15.858-84.598-10.57-24.928-23.428-45.29-38.43-60.972-15.002-15.74-30.048-30.128-45.092-43.074-15.046-12.976-27.904-26.506-38.436-40.55-10.614-14-15.894-28.474-15.894-43.476 0-15.024 6.854-30.288 20.524-45.67 13.62-15.426 30.376-30.376 50.19-45.144 19.85-14.666 39.658-30.946 59.472-48.662 19.858-17.694 36.52-40.456 50.14-68.096 13.722-27.744 20.568-58.288 20.568-91.86 0-44.288-11.294-84.282-33.806-119.882-22.58-35.446-51.998-63.73-88.144-84.472-36.242-20.882-75-36.6-116.334-47.214-41.42-10.518-82.52-15.806-123.568-15.806-25.908 0-52.048 1.996-78.336 6.1-26.382 4.096-52.81 11.33-79.426 21.526-26.668 10.262-50.286 22.864-70.758 37.998-20.524 14.98-37.046 34.312-49.716 57.856-12.668 23.552-18.958 50.022-18.958 79.426 0 34.882 9.714 67.24 29.192 97.404 19.478 29.944 45.282 54.952 77.378 74.76 55.998 34.838 143.858 56.364 263.432 64.498-27.334 34.172-41.048 66.334-41.048 96.432 0 17.122 4.476 35.474 13.334 55.288-14.284-1.996-28.994-3.124-44.002-3.124-64.234 0-118.476 20.882-162.524 62.932-44.046 41.976-66.048 94.522-66.048 158.048 0 6.642 0.19 12.492 0.672 18.974h-261.046l393.618 342.17h651.856l-60.24-47.024v-82.996c22.368-2.874 20.004-16.318 20.004-32.394zM900.382 544.929c-7.52 1.36-18.088 2.122-31.708 2.122-29.382 0-58.288-2.596-86.666-7.782-28.38-5.046-56.378-13.568-83.998-25.592-27.722-11.952-50.096-29.528-67.146-52.766-17.144-23.208-25.666-50.542-25.666-81.994 0-29.974 7.52-56.714 22.572-80.004 15.002-23.142 34.808-41.26 59.428-54.236 24.62-12.998 50.432-22.814 77.378-29.264 26.998-6.408 54.476-9.736 82.476-9.736 55.376 0 103.050 12.47 143.046 37.406 39.906 24.928 59.904 63.422 59.904 115.382 0 10.928-1.522 21.686-4.528 32.19-3.138 10.62-6.24 19.712-9.282 27.26-3.050 7.41-8.858 16.332-17.43 26.616-8.522 10.314-15.046 17.934-19.434 23.004-4.476 5.238-12.852 12.712-25.19 22.594-12.236 9.926-20.048 16.114-23.522 18.402-3.43 2.406-12.332 8.908-26.668 19.456-14.328 10.634-22.184 16.274-23.566 16.94z" /></svg>

    </a>
  
  <!--<a id="subscribe-link"
     class="icon" title="Subscribe" aria-label="Subscribe"
     href="/feed.xml">
    <svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M0 0h24v24H0z" fill="none"/>
    <circle cx="6.18" cy="17.82" r="2.18"/>
    <path d="M4 4.44v2.83c7.03 0 12.73 5.7 12.73 12.73h2.83c0-8.59-6.97-15.56-15.56-15.56zm0 5.66v2.83c3.9 0 7.07 3.17 7.07 7.07h2.83c0-5.47-4.43-9.9-9.9-9.9z"/>
</svg>
  </a>

  
  
  
  

  
    <a id="tags-link"
       class="icon"
       title="Tags" aria-label="Tags"
       href="/tags.html">
      <svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M0 0h24v24H0z" fill="none"/>
    <path d="M17.63 5.84C17.27 5.33 16.67 5 16 5L5 5.01C3.9 5.01 3 5.9 3 7v10c0 1.1.9 1.99 2 1.99L16 19c.67 0 1.27-.33 1.63-.84L22 12l-4.37-6.16z"/>
</svg>
    </a>
  

  
    <a id="search-link"
       class="icon"
       title="Search" aria-label="Tags"
       href="/search.html">
      <svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"/>
    <path d="M0 0h24v24H0z" fill="none"/>
</svg>
    </a>
  -->

  <!-- Optional additional links to insert for icons links -->
</nav>
 </center>
  <p style="font-size:80%;">
  <!--(Site last updated: Nov, 2023)
  <br /> -->
  <a href="https://github.com/fongandrew/hydeout">Theme by Hydeout</a>
</p>

  </center>
</div>


    <main class="container">
      <div class="content">
  

  
  

  

  
  

  

  
  

  

  
  <article class="post-body">

    <div class="post-meta">
  <span class="post-date"></span>
  <span class="post-categories">
    
  </span>
</div>

    <style>

table {
  margin-bottom: 1rem;
  width: 100%;
  font-size: 85%;
  border: 0px solid $border-color;
  border-collapse: collapse;
}

td,
th {
  padding: 1rem .25rem;
  border: 0px solid $border-color;
}

th {
  text-align: left;
}

tbody tr:nth-child(odd) td,
tbody tr:nth-child(odd) th {
  background-color: transparent;
}

paper {
 color: #; 
 font-weight:bold;
}

</style>

<p><br /></p>

<!--<img align="left" width=150px src="/images/dp.jpg"> -->

<p>I work as a postdoc for <a href="https://cs.stanford.edu/people/ebrun/">Prof. Emma Brunskill</a> at <a href="https://www.stanford.edu/">Stanford University</a>. 
I received my PhD at the <a href="https://www.umass.edu/">University of Massachusetts</a>, where I was fortunate to be advised by <a href="https://people.cs.umass.edu/~pthomas/">Prof. Philip Thomas</a>.
<br /><br />
My Resume/CV can be found <a href="/docs/Resume.pdf">here</a>. (I am on the job market)</p>

<p><br /></p>

<h2 id="research-interests">Research Interests</h2>

<p>Click <a href="/publication">here</a> for all the publications.</p>

<h3 id="formal-reasoning--decision-making-with-foundation-models">Formal Reasoning &amp; Decision-Making with Foundation Models</h3>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">


<tr>
       <td width="14%" valign="top">
            <img src="/images/publications/web_LEAN.png" alt="lean" style="vertical-align:top; width: 80%; margin:0px 10px; border-radius:0%" /> 
     </td>
     <td valign="top" width="85%">
          <p>
              <paper>Neural Theorem Proving with Information Directed Search</paper>
              <br />  
              <b>Yash Chandak</b>,    
              <a href="https://jonathannlee.com/">Jonathan N. Lee</a>,
              <a href="https://cs.stanford.edu/people/ebrun/">Emma Brunskill</a>.
            <br />
       In preparation.
       <br /><br />
       Abstract: Formal reasoning tasks are challenging to solve but often there is availability of rich feedback, unlike a scalar feedback in the classical RL setting. How do we combine LLMs and RL to obtain the best of both for long-horizon (formal) reasoning?   
          </p>  
     </td>
   </tr> 
    
  <tr>
       <td width="14%" valign="top">
            <img src="/images/publications/web_DPT.png" alt="DPT" style="vertical-align:top; width: 80%; margin:0px 10px; border-radius:0%" /> 
     </td>
     <td valign="top" width="85%">
          <p>
              <paper>Supervised Pretraining Can Learn In-Context Reinforcement Learning </paper>
              <br />  
              <a href="https://jonathannlee.com/">Jonathan N. Lee</a>,
              <a href="https://anxie.github.io/">Annie Xie</a>,
              <a href="https://www.aldopacchiano.ai/">Aldo Pacchiano</a>,
              <b>Yash Chandak</b>,    
              <a href="https://ai.stanford.edu/~cbfinn/">Chelsea Finn</a>,
              <a href="https://ofirnachum.github.io/">Ofir Nachum</a>,
              <a href="https://cs.stanford.edu/people/ebrun/">Emma Brunskill</a>.
            <br />
            <b>(Spotlight)</b> Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS 2023). <a href="https://arxiv.org/abs/2306.14892">[Pdf]</a>
       <br /><br />
       Abstract: Can supervised pre-training provide in-context capabilities to solve decision-making problems? Perhaps surprisingly, drawing formal connections to posterior sampling, in-context interaction with the same model can result in conservative behavior in the offline setting, and also optimistic exploration in the online setting.  
          </p>  
     </td>
  </tr> 
  </table>

<h3 id="strategic-data-collection--reward-design">Strategic Data Collection &amp; Reward Design</h3>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
     
<tr>
       <td width="14%" valign="top">
            <img src="/images/publications/web_DIA.png" alt="DIA" style="vertical-align:top; width: 80%; margin:0px 10px; border-radius:0%" /> 
     </td>
     <td valign="top" width="85%">
          <p>
              <paper>Adaptive Instrument Design for Indirect Experiments</paper>
              <br />  
              <b>Yash Chandak</b>,    
              <a href="https://scholar.google.com/citations?user=yK56jugAAAAJ&amp;hl=en">Shiv Shankar</a>,
              <a href="https://vsyrgkanis.com/">Vasilis Syrgkanis</a>,
              <a href="https://cs.stanford.edu/people/ebrun/">Emma Brunskill</a>.
            <br />
            Under review.
       <br /><br />
       Abstract: In human-AI systems, AI can only be suggestive and not prescriptive about what a human should do (e.g., how should a student interact with LLMs to learn quicker). In such cases, how should AI systems interact strategically to quickly estimate what would have happened had the human complied to its suggestions?  
          </p>  
     </td>
   </tr> 

<tr>
       <td width="14%" valign="top">
            <img src="/images/publications/web_BARFI.png" alt="BARFI" style="vertical-align:top; width: 80%; margin:0px 10px; border-radius:0%" /> 
     </td>
     <td valign="top" width="85%">
          <p>
              <paper>Behavior Alignment via Reward Function Optimization</paper>
              <br />  
              <a href="https://dhawgupta.com/">Dhawal Gupta</a>*,
              <b>Yash Chandak</b>*,    
              <a href="https://scottjordan.github.io/scottjordan/">Scott Jordan</a>,
              <a href="https://people.cs.umass.edu/~pthomas/">Philip Thomas</a>,
              <a href="https://people.cs.umass.edu/~bsilva/">Bruno Castro da Silva</a>.
            *Equal contribution
            <br />
            <b>(Spotlight)</b> Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS 2023).  <a href="https://arxiv.org/abs/2310.19007">[Pdf]</a>
       <br /><br />
       Abstract: How should we leverage side-information to design reward functions that are dense, yet aligned with a user's goal? We show that the classic approach of reward shaping has several limitations, and propose a new bi-level reward alignment procedure to address the challenges. 
        </p>  
     </td>
  </tr> 
  </table>

<!-- 
### Reinforcement Learning for Non-stationary Environments

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
<tr>
     <td width="14%"  valign="top">
            <img src="/images/publications/web_UnO.png" alt="UnO" style="vertical-align:top; width: 80%; margin:0px 10px; border-radius:0%"/> 
     </td>
     <td valign="top" width="85%">
          <p>
              <paper>Universal Off-Policy Evaluation</paper>
              <br>
              <b>Yash Chandak</b>,  
              <a href='https://www.cs.utexas.edu/~sniekum/'>Scott Niekum</a>,
              <a href='https://people.cs.umass.edu/~bsilva/'>Bruno Castro da Silva</a>,
              <a href='https://people.cs.umass.edu/~elm/'>Erik Learned-Miller</a>,
              <a href='https://cs.stanford.edu/people/ebrun/'>Emma Brunskill</a>,
              <a href='https://people.cs.umass.edu/~pthomas/'>Philip Thomas</a>
              <br>
             Thirty-fifth Conference on Neural Information Processing Systems (NeurIPS 2021). <a href="https://arxiv.org/abs/2104.12820">[Pdf]</a> 
            <br>
              <font color='red'>Best Paper</font> award at the Conference on Reinforcement Learning and Decision Making (RLDM 2022).
          </p>  
     </td>
   </tr>
   <tr>
     <td width="14%"  valign="top">
            <img src="/images/publications/prognosticator.png" alt="Future" style="vertical-align:top; width: 80%; margin:0px 10px; border-radius:0%"/> 
     </td>
     <td valign="top" width="85%">
          <p>
              <paper>Optimizing for the Future in Non-Stationary MDPs</paper>
              <br>
              <b>Yash Chandak</b>, 
              <a href='https://research.adobe.com/person/georgios-theocharous/'>Georgios Theocharous</a>,   
              <a href='https://scholar.google.com/citations?user=yK56jugAAAAJ&hl=en'>Shiv Shankar</a>,
              <a href='https://webdocs.cs.ualberta.ca/~whitem/'>Martha White</a>,   
              <a href='https://people.cs.umass.edu/~mahadeva/Site/About_Me.html'>Sridhar Mahadevan</a>,  
              <a href='https://people.cs.umass.edu/~pthomas/'>Philip Thomas</a>
              <br>
              Thirty-seventh International Conference on Machine Learning (ICML 2020). <a href="https://arxiv.org/abs/2005.08158">[Pdf]</a> 
          </p>  
     </td>
   </tr>

  </table>

 -->

<!-- ## Recent 

- Our papers on (a) Behavior Alignment via Reward Function Optimization, and (b) Supervised Pretraining Can Learn In-Context Reinforcement Learning, got spotlight acceptance at NeurIPS'23.
- Our papers on (a) Representations and Exploration for Deep Reinforcement Learning using Singular Value Decomposition, and (b) Understanding Self-Predictive Learning for Reinforcement Learning, got accepted at ICML'23.
- Our paper on obtaining asymptotically unbiased off-policy policy evaluation when reusing old data in nonstationary environments got accepted at AISTATS'23.
- Our papers on (a) Off-Policy evaluation for action-dependent non-stationary environments, and (b) Factored distributionally robust policies for contextual bandits, got accepted at NeurIPS'22.
- PhD done. Graduated! Thanks to Phil for making my PhD journey amazing!
- RLDM 2022 best paper award for our work on universal off-policy evaluation.
<br><br> -->



  </article>
  
  

  

  
  

  

  
  

  

  
  

  

  
  

  

  
  

  

  
  

  

  
  
</div>
    </main>

    <!-- Optional footer content -->

    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-128250681-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-128250681-1');
</script>

  </body>
</html>
